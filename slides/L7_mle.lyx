#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass beamer
\begin_preamble


% you can play with different themes and color themes to find your favorite combination.
\mode<presentation> {
  \usetheme{Luebeck}
  \usecolortheme{beaver}
  \beamertemplatenavigationsymbolsempty
 
}

\usepackage{mathtools}
\usepackage{graphicx} % for including images
\usepackage{pgf} % for logo
\usepackage{colortbl}
\usepackage{booktabs}
\usepackage{emoji}
\usepackage{listings}
\usepackage[many]{tcolorbox}
\usepackage{tabularx}
\usepackage{array}
\tcbuselibrary{skins}
\usepackage{pstricks}
%\usepackage{fdsymbol} % for card symbols


\newcolumntype{Y}{>{\raggedleft\arraybackslash}X}
\tcbset{tab2/.style={enhanced, fontupper=\small,
colback=lightgray!10!white,colframe=cobalt!50!black,colbacktitle=lightsteelblue!40!white,
coltitle=black,center title}}

\newcommand\boldblue[1]{\textcolor{cobalt}{\textbf{#1}}}
\newcommand\boldorange[1]{\textcolor{burntoranger}{\textbf{#1}}}
\def\*#1{\mathbf{#1}}

\date{} % Date, can be changed to a custom date

\titlegraphic{
\vspace{-0.6cm}
\includegraphics[width=1.5cm]{/misc/LogoBlueJustRing.jpg}\break


\tiny
\vspace{1cm}
\href{https://mattiasvillani.com}{\includegraphics[width=0.33cm]{/misc/web.png} mattiasvillani.com}\hspace*{1cm}~
\href{https://twitter.com/matvil}{\includegraphics[width=0.3cm]{/misc/bluesky.png} @matvil}\hspace*{1cm}~
\href{https://fosstodon.org/@matvil}{\includegraphics[width=0.3cm]{/misc/mastodon.pdf} @matvil}\hspace*{1cm}~
\href{https://github.com/mattiasvillani}{\includegraphics[width=0.3cm]{/misc/github.png} mattiasvillani}~
}


\definecolor{blue}{RGB}{38, 122, 181}
\definecolor{orange}{RGB}{255, 128, 0}
\definecolor{lorange}{RGB}{255, 178, 102}
\definecolor{llorange}{RGB}{255, 229,204 }
\definecolor{verylightgray}{RGB}{246, 246, 246}
\definecolor{cobalt}{HTML}{0047AB}
\definecolor{lightsteelblue}{HTML}{b0c4de}

\definecolor{bookblue}{HTML}{6C8EBF}
\definecolor{bookgold}{HTML}{C0A34D}
\definecolor{bookred}{HTML}{780000}


\definecolor{shadecolor}{rgb}{236, 236, 236}

\setbeamertemplate{itemize item}{\color{orange}$\blacksquare$}
\setbeamertemplate{itemize subitem}{\color{orange}$\blacktriangleright$}
\usepackage{tcolorbox}



\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}

\setbeamertemplate{footline}{}
\end_preamble
\options xcolor=svgnames
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "palatino" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\boxbgcolor #bfbc40
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\size largest
\color orange
Statistical Theory and Modeling (ST2601)
\begin_inset Newline newline
\end_inset


\size default
Lecture 7 - Point estimation and Maximum likelihood
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\color gray
STM course
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hspace{2.7cm}
\backslash
insertframenumber/
\backslash
inserttotalframenumber
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Author
Mattias Villani
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\series bold
\color gray
Mattias Villani
\end_layout

\end_inset


\end_layout

\begin_layout Institute

\series bold
Department of Statistics
\begin_inset Newline newline
\end_inset

Stockholm University
\series default

\begin_inset Argument 1
status open

\begin_layout Plain Layout
Stockholm University
\end_layout

\end_inset


\end_layout

\begin_layout Date
\begin_inset space \thinspace{}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Overview
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
Maximum likelihood
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Sampling distributions
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Bias-variance trade-off
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Consistency
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Sufficiency
\begin_inset VSpace bigskip
\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Probability vs Inference
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
Probability theory
\series default
\color inherit
: 
\series bold
\color orange
given a distribution with parameter 
\begin_inset Formula $\theta$
\end_inset

 
\series default
\color inherit
what are the properties of random variables (data)?
\series bold
\color blue

\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $X\sim\mathrm{Pois}(\lambda$
\end_inset

).
 Then: 
\begin_inset Formula $\mathbb{E}(X)=\lambda$
\end_inset

 and 
\begin_inset Formula $\mathbb{V}(X)=\lambda$
\end_inset

.
 
\series bold
\color blue

\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize
What is 
\begin_inset Formula $\mathrm{Pr}(X>4)$
\end_inset

 for a given 
\begin_inset Formula $\lambda$
\end_inset

?
\series bold
\color blue

\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $X_{1},\ldots,X_{n}\sim\mathrm{Pois}(\lambda$
\end_inset

) for a given 
\begin_inset Formula $\lambda$
\end_inset

, what is 
\begin_inset Formula $\mathbb{E}(\bar{X}_{n})$
\end_inset

? 
\series bold
\color blue

\begin_inset VSpace bigskip
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
\color blue
Inference
\series default
\color inherit
/
\series bold
\color blue
Learning
\series default
\color inherit
: 
\series bold
\color orange
given observed data 
\begin_inset Formula $x_{1},\ldots,x_{n}$
\end_inset


\series default
\color inherit
, which distribution and parameter value 
\begin_inset Formula $\theta$
\end_inset

 generated the data?
\series bold
\color blue

\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
Point estimation
\series default
\color inherit
 
\begin_inset Formula $\hat{\lambda}=\bar{x}$
\end_inset


\series bold
\color blue

\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Uncertainty quantification
\series default
\color inherit
:
\end_layout

\begin_deeper
\begin_layout Itemize
standard errors 
\begin_inset Formula $\mathbb{S}(\hat{\lambda})$
\end_inset


\end_layout

\begin_layout Itemize
confidence intervals
\end_layout

\begin_layout Itemize
Bayesian posterior distributions 
\begin_inset Graphics
	filename emojis/HeartEyesEmoji.png
	lyxscale 5
	scale 2

\end_inset


\series bold
\color blue

\begin_inset VSpace bigskip
\end_inset


\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Probability vs Inference
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
Probability theory
\series default
\color inherit
: Models and Parameters 
\begin_inset Formula $\Longrightarrow$
\end_inset

 Data.
\series bold
\color blue

\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Inference
\series default
\color inherit
: Data 
\begin_inset Formula $\Longrightarrow$
\end_inset

 Models and Parameters 
\begin_inset Formula $\rightsquigarrow$
\end_inset

 Reality
\series bold
\color blue

\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize
Often described as (particularly in finite populations):
\series bold
\color blue

\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Probability theory
\series default
\color inherit
: Population 
\begin_inset Formula $\Longrightarrow$
\end_inset

 Sample
\series bold
\color blue

\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Inference
\series default
\color inherit
: Sample 
\begin_inset Formula $\Longrightarrow$
\end_inset

 Population
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename /home/mv/Dropbox/PreBayesBook/Figs/Population_sample.pdf
	lyxscale 30
	scale 40

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
The big picture of Statistics
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename /home/mv/Dropbox/PreBayesBook/Figs/model_reality.pdf
	lyxscale 40
	scale 32

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
The likelihood function
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
Probability distribution
\series default
\color inherit
 for the dataset: 
\begin_inset Formula $p(X_{1},X_{2},\ldots,X_{n}\vert\theta)$
\end_inset

.
 
\end_layout

\begin_layout Itemize

\series bold
\color blue
Probability for the observed data
\series default
\color inherit
 
\begin_inset Formula $p(x_{1},x_{2},\ldots,x_{n}\vert\theta)$
\end_inset

.
\series bold
\color blue

\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color orange
Inference
\series default
\color inherit
: given observed data 
\begin_inset Formula $x_{1},\ldots,x_{n}$
\end_inset

, what is a 
\begin_inset Quotes eld
\end_inset

good
\begin_inset Quotes erd
\end_inset

 value for 
\begin_inset Formula $\theta$
\end_inset

?
\series bold
\color blue

\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize
Good values for 
\begin_inset Formula $\theta$
\end_inset

 
\begin_inset Formula $\Longleftrightarrow$
\end_inset

 high probability for the observed data.
\series bold
\color blue

\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize
Bad values for 
\begin_inset Formula $\theta$
\end_inset

 
\begin_inset Formula $\Longleftrightarrow$
\end_inset

 low probability for the observed data.
\series bold
\color blue

\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize
Find parameter value 
\begin_inset Formula $\theta$
\end_inset

 that 
\series bold
\color blue
maximizes
\series default
\color inherit
 the 
\series bold
\color blue
likelihood function
\series default
\color inherit

\begin_inset Formula 
\[
p(x_{1},\ldots,x_{n}\vert\theta)
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Different notations for the likelihood function
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $p(x_{1},\ldots,x_{n}\vert\theta)$
\end_inset

 
\begin_inset Formula $\,$
\end_inset

[My Bayesian 
\begin_inset Graphics
	filename emojis/ChefskissEmoji.png
	lyxscale 5
	scale 2

\end_inset

 preference]
\series bold
\color blue

\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $L(x_{1},\ldots,x_{n}\vert\theta)$
\end_inset

 
\begin_inset Formula $\,$
\end_inset

[
\begin_inset Formula $L$
\end_inset

 instead of 
\begin_inset Formula $p$
\end_inset

 is for Likelihood]
\series bold
\color blue

\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $L(\theta)$
\end_inset

 
\begin_inset space \hspace{}
\length 1.5cm
\end_inset


\begin_inset Formula $\,$
\end_inset

 [Hiding the data.
 But convenient.]
\series bold
\color blue

\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $L(x_{1},\ldots,x_{n};\theta)$
\end_inset

 [Well, now we're just doing random symbols?]
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Likelihood function - bit by bit
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\bar under
\color blue
\begin_inset CommandInset href
LatexCommand href
name "eBay auction data"
target "https://github.com/mattiasvillani/BayesianLearningBook/raw/main/data/ebaybids/ebaybids.csv"
literal "false"

\end_inset


\bar default
\color inherit
 with 1000 auctions for collectors' coins.
\end_layout

\begin_layout Itemize
We focus here on the number of bidders in the auctions.
\end_layout

\begin_layout Itemize
Count data: let's try a Poisson!
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename figs/ebaydata.png
	scale 15

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename /home/mv/Dropbox/PreBayesBook/Figs/eBayBids.pdf
	scale 25

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Likelihood function for the first observation 
\begin_inset Formula $y_{1}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
First data point: 
\begin_inset Formula $y_{1}=2$
\end_inset

.
 
\end_layout

\begin_layout Itemize
Probability of observing 
\begin_inset Formula $y_{1}=2$
\end_inset

 in the Poisson model?
\end_layout

\begin_layout Itemize
Poisson probability function:
\begin_inset Formula 
\[
p(Y_{1}=y_{1}\vert\lambda)=\frac{\lambda^{y_{1}}e^{-\lambda}}{y_{1}!}=\frac{\lambda^{2}e^{-\lambda}}{2!}
\]

\end_inset


\end_layout

\begin_layout Itemize
Let's try with 
\begin_inset Formula $\lambda=3$
\end_inset

.
 
\end_layout

\begin_deeper
\begin_layout Itemize
Mathematically:
\begin_inset Formula 
\[
p(Y_{1}=2\vert\lambda=3)=\frac{3^{2}e^{-3}}{2!}=0.2240418
\]

\end_inset


\end_layout

\begin_layout Itemize
In R: 
\family typewriter
dpois(x = 2, lambda = 3)
\end_layout

\end_deeper
\begin_layout Itemize
For 
\begin_inset Formula $\lambda=2$
\end_inset

: 
\end_layout

\begin_deeper
\begin_layout Itemize
Mathematically:
\begin_inset Formula 
\[
p(Y_{1}=2\vert\lambda=2)=\frac{2^{2}e^{-2}}{2!}=0.2706706
\]

\end_inset


\end_layout

\begin_layout Itemize
In R: 
\family typewriter
dpois(x = 2, lambda = 2)
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Likelihood function for the first observation 
\begin_inset Formula $y_{1}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
So, 
\begin_inset Formula $\lambda=2$
\end_inset

 gave a higher probability to the data 
\begin_inset Formula $y_{1}=2$
\end_inset

 compared to 
\begin_inset Formula $\lambda=3$
\end_inset

.
\end_layout

\begin_layout Itemize
How about other 
\begin_inset Formula $\lambda$
\end_inset

 values? Let's do them all!
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename /home/mv/Dropbox/PreBayesBook/Figs/eBayLikeOneObs.pdf
	lyxscale 40
	scale 30

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Likelihood function for 
\begin_inset Formula $y_{1}$
\end_inset

 and 
\begin_inset Formula $y_{2}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Data: 
\begin_inset Formula $y_{1}=2$
\end_inset

 and 
\begin_inset Formula $y_{2}=6$
\end_inset

.
\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Itemize
Likelihood function is the 
\series bold
\color blue
joint probability
\series default
\size footnotesize
\color inherit

\begin_inset Formula 
\[
p(Y_{1}=2,Y_{2}=6\vert\lambda)\overset{\mathrm{indep}}{=}p(Y_{1}=2\vert\lambda)\cdot p(Y_{2}=6\vert\lambda)=\frac{\lambda^{y_{1}}e^{-\lambda}}{y_{1}!}\cdot\frac{\lambda^{y_{2}}e^{-\lambda}}{y_{2}!}
\]

\end_inset


\end_layout

\begin_layout Itemize
For 
\begin_inset Formula $\lambda=2$
\end_inset


\begin_inset Formula 
\[
p(Y_{1}=2,Y_{2}=6\vert\lambda=2)=\frac{2^{2}e^{-2}}{2!}\cdot\frac{2^{6}e^{-2}}{6!}
\]

\end_inset


\end_layout

\begin_layout Itemize
Let R do the work 
\end_layout

\begin_layout Standard
\align center

\family typewriter
\size footnotesize
dpois(x = 2, lambda = 2)*dpois(x = 6, lambda = 2) = 0.003256114
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename /home/mv/Dropbox/PreBayesBook/Figs/eBayLikeTwoObs.pdf
	lyxscale 40
	scale 25

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Likelihood function for 
\begin_inset Formula $y_{1},\ldots,y_{10}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Likelihood function using first ten observations
\begin_inset Formula 
\[
p(Y_{1}=y_{1},\ldots,Y_{10}=y_{10}\vert\lambda)\overset{\mathrm{indep}}{=}\prod_{i=1}^{10}p(y_{i}\vert\lambda)
\]

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename /home/mv/Dropbox/PreBayesBook/Figs/eBayLikeTenObs.pdf
	lyxscale 40
	scale 25

\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Likelihood function
\series default
\color inherit
 for all 
\begin_inset Formula $n=1000$
\end_inset

 observations
\begin_inset Formula 
\[
p(Y_{1}=y_{1},\ldots,Y_{n}=y_{n}\vert\lambda)=\prod_{i=1}^{n}p(y_{i}\vert\lambda)
\]

\end_inset


\end_layout

\begin_layout Itemize
Product of 
\begin_inset Formula $1000$
\end_inset

 probabilities is a tiny number.
 Let's do logs.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Log-likelihood function for two observations
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Log-Likelihood function using first two observations
\begin_inset Formula 
\[
\log p(Y_{1}=2,Y_{2}=6\vert\lambda)=\log p(Y_{1}=2\vert\lambda)+\log p(Y_{2}=6\vert\lambda)
\]

\end_inset


\end_layout

\begin_layout Standard
\align center
Â´
\begin_inset Graphics
	filename /home/mv/Dropbox/PreBayesBook/Figs/eBayLikeFirstTwoObsSimple.pdf
	lyxscale 40
	scale 25

\end_inset


\begin_inset Graphics
	filename /home/mv/Dropbox/PreBayesBook/Figs/eBayLogLikeFirstTwoObs.pdf
	lyxscale 40
	scale 25

\end_inset


\end_layout

\begin_layout Itemize
Note: since 
\begin_inset Formula $\log$
\end_inset

 is monotonically increasing transformation: the 
\begin_inset Formula $\lambda$
\end_inset

 that maximizes the likelihood is the same 
\begin_inset Formula $\lambda$
\end_inset

 that maximizes the log-likelihood.
\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Maximum likelihood estimator
\series default
\color inherit
 of 
\begin_inset Formula $\lambda$
\end_inset

: the value of 
\begin_inset Formula $\lambda$
\end_inset

 that maximizes the (log-)likehood function.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Log-likelihood function for all observations
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
Log-likelihood
\series default
\color inherit
 for all 
\begin_inset Formula $n$
\end_inset

 data points
\begin_inset Formula 
\[
\ell(\lambda)=\log L(\lambda)=\sum_{i=1}^{n}\log p(y_{i}\vert\lambda)
\]

\end_inset


\end_layout

\begin_layout Itemize
Poisson distribution
\begin_inset Formula 
\[
p(y_{i}\vert\lambda)=\frac{\lambda^{y_{i}}e^{-\lambda}}{y_{i}!}\quad\text{ and }\quad\log p(y_{i}\vert\lambda)=y_{i}\log\lambda-\lambda-\log(y_{i}!)
\]

\end_inset


\end_layout

\begin_layout Itemize
Log-likelihood for iid Poisson model
\size footnotesize

\begin_inset Formula 
\begin{align*}
\ell(\lambda) & =\sum_{i=1}^{n}\log p(y_{i}\vert\lambda)=\sum_{i=1}^{n}\left(y_{i}\log\lambda-\lambda-\log(y_{i}!)\right)\\
 & =\log\lambda\sum_{i=1}^{n}y_{i}-n\lambda-\sum_{i=1}^{n}\log(y_{i}!)
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize
Since 
\begin_inset Formula $\sum_{i=1}^{n}y_{i}=n\bar{y}$
\end_inset

 we can write
\begin_inset Formula 
\[
\ell(\lambda)=\log\lambda\cdot n\bar{y}-n\lambda-\sum_{i=1}^{n}\log(y_{i}!)
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Log-likelihood function for all observations
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Log-likelihood for 
\series bold
\color blue
iid Poisson model
\series default
\color inherit

\begin_inset Formula 
\[
\ell(\lambda)=\log\lambda\cdot n\bar{y}-n\lambda-\sum_{i=1}^{n}\log(y_{i}!)
\]

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename /home/mv/Dropbox/PreBayesBook/Figs/eBayLogLikeAllObs.pdf
	scale 35

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
The MLE in the iid Poisson model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
Maximum likelihood
\series default
\color inherit
 (
\series bold
\color blue
MLE
\series default
\color inherit
) of 
\begin_inset Formula $\lambda$
\end_inset


\begin_inset Formula 
\[
\hat{\lambda}_{ML}=\underset{\lambda}{\mathrm{arg}\mathrm{max}}\:\ell(\lambda)
\]

\end_inset


\end_layout

\begin_layout Itemize
Finding a maximum of a function? Set first derivate to zero and solve for
 
\begin_inset Formula $\lambda$
\end_inset


\begin_inset Formula 
\[
\ell'(\lambda)=0
\]

\end_inset


\end_layout

\begin_layout Itemize
Check for (local) maximum by checking second derivative 
\begin_inset Formula 
\[
\ell''(\hat{\lambda}_{ML})<0
\]

\end_inset


\end_layout

\begin_layout Itemize
When 
\begin_inset Formula $\ell'(\lambda)=0$
\end_inset

 cannot be solved mathematically.
 Use computer.
 More later!
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
The MLE in the iid Poisson model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Log-likelihood
\begin_inset Formula 
\[
\ell(\lambda)=\log\lambda\cdot n\bar{y}-n\lambda-\sum_{i=1}^{n}\log(y_{i}!)
\]

\end_inset


\begin_inset Formula 
\[
\ell'(\lambda)=\frac{n\bar{y}}{\lambda}-n=0
\]

\end_inset

has solution
\begin_inset Formula 
\[
\hat{\lambda}_{ML}=\bar{y}
\]

\end_inset


\end_layout

\begin_layout Itemize
Second derivative shows that this indeed a (local) maximizer
\begin_inset Formula 
\[
\ell''(\lambda)=\frac{\mathrm{d}}{\mathrm{d}\lambda}\ell'(\lambda)=-\frac{n\bar{y}}{\lambda^{2}}<0
\]

\end_inset

for all 
\begin_inset Formula $\lambda$
\end_inset

 and therefore also at 
\begin_inset Formula $\hat{\lambda}_{ML}$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
The MLE in the iid Exponential model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Model
\begin_inset Formula 
\[
Y_{1},\ldots,Y_{n}\overset{\mathrm{iid}}{\sim}\mathrm{Expon}(\beta)
\]

\end_inset


\end_layout

\begin_layout Itemize
Likelihood (densities because of continuous random variables!)
\size footnotesize

\begin_inset Formula 
\[
L(\beta)=\prod_{i=1}^{n}f(y_{i}\vert\beta)=\prod_{i=1}^{n}\frac{1}{\beta}e^{-y_{i}/\beta}=\frac{1}{\beta^{n}}e^{-\frac{1}{\beta}\sum_{i=1}^{n}y_{i}}=\frac{1}{\beta^{n}}e^{-\frac{n\bar{y}}{\beta}}
\]

\end_inset


\end_layout

\begin_layout Itemize
Log-likelihood
\size footnotesize

\begin_inset Formula 
\[
\ell(\beta)=\log L(\beta)=-n\log\beta-\frac{n\bar{y}}{\beta}
\]

\end_inset


\begin_inset Formula 
\[
\ell'(\beta)=-\frac{n}{\beta}+\frac{n\bar{y}}{\beta^{2}}=0
\]

\end_inset


\begin_inset Formula 
\[
-n+\frac{n\bar{y}}{\beta}=0
\]

\end_inset


\size default
so
\size footnotesize

\begin_inset Formula 
\[
\hat{\beta}_{ML}=\bar{y}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
The MLE in the iid Exponential model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
First derivative
\begin_inset Formula 
\[
\ell'(\beta)=-\frac{n}{\beta}+\frac{n\bar{y}}{\beta^{2}}
\]

\end_inset


\end_layout

\begin_layout Itemize
Second derivative
\begin_inset Formula 
\[
\ell''(\beta)=\frac{n}{\beta^{2}}-\frac{2n\bar{y}}{\beta^{3}}
\]

\end_inset


\end_layout

\begin_layout Itemize
Evaluate at 
\series bold

\begin_inset Formula $\hat{\beta}_{ML}=\bar{y}$
\end_inset


\series default

\begin_inset Formula 
\[
\ell''(\hat{\beta}_{ML})=\frac{n}{\bar{y}^{2}}-\frac{2n\bar{y}}{\bar{y}^{3}}=\frac{n}{\bar{y}^{2}}-\frac{2n}{\bar{y}^{2}}=-\frac{n}{\bar{y}^{2}}<0
\]

\end_inset

since 
\begin_inset Formula $n>0$
\end_inset

 and 
\begin_inset Formula $\bar{y}>0$
\end_inset

 (exponential is used for positive data).
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Sampling distribution of an estimator
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
An estimator 
\begin_inset Formula $\hat{\theta}$
\end_inset

 depends on the sample
\begin_inset Formula 
\[
\hat{\theta}_{n}(X_{1},\ldots,X_{n})
\]

\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Sampling distribution
\series default
\color inherit
 of 
\begin_inset Formula $\hat{\theta}$
\end_inset

 tells us how 
\begin_inset Formula $\hat{\theta}$
\end_inset

 varies 
\series bold
\color orange
from sample to sample
\series default
\color inherit
.
\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Confidence intervals
\series default
\color inherit
 are based on this.
\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Asymptotic sampling distribution
\series default
\color inherit
 for 
\begin_inset Formula $\hat{\theta}_{n}$
\end_inset

: what is the sampling distribution when 
\begin_inset Formula $n$
\end_inset

 is large (
\begin_inset Formula $n\rightarrow\infty$
\end_inset

).
\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Central limit theorem
\series default
\color inherit
: the asymptotic sampling distribution of the sample mean 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 is normal.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Bias-variance trade-off
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
Unbiased estimator 
\series default
\color inherit

\begin_inset Formula 
\[
\mathbb{E}(\hat{\theta})=\theta
\]

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename /home/mv/Dropbox/BayesBook/Figs/Bias_bullseye.pdf
	lyxscale 40
	scale 35

\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Bias
\series default
\color inherit

\begin_inset Formula 
\[
\mathbb{E}(\hat{\theta})-\theta
\]

\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Mean square error
\series default
\color inherit
 (MSE)
\begin_inset Formula 
\[
\mathbb{E}(\hat{\theta}-\theta)^{2}=\mathbb{V}(\hat{\theta})+\left(\mathrm{Bias}(\hat{\theta})\right)^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename /home/mv/Dropbox/BayesBook/Figs/Bias_variance_bullseye.pdf
	lyxscale 40
	scale 35

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Consistent estimator
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Law of large numbers
\begin_inset Formula 
\[
\bar{X}_{n}\overset{p}{\rightarrow}\mu
\]

\end_inset


\end_layout

\begin_layout Itemize
An estimator 
\begin_inset Formula $\hat{\theta}$
\end_inset

 is 
\series bold
\color blue
consistent
\series default
\color inherit
 for a population parameter 
\begin_inset Formula $\theta$
\end_inset

 if
\begin_inset Formula 
\[
\hat{\theta}_{n}\overset{p}{\rightarrow}\theta
\]

\end_inset

which, by convergence in probability, means that for any 
\begin_inset Formula $\epsilon>0$
\end_inset


\begin_inset Formula 
\[
\mathrm{Pr}(\vert\hat{\theta}_{n}-\theta\vert>\epsilon)\rightarrow0\quad\text{ as }n\rightarrow\infty
\]

\end_inset


\end_layout

\begin_layout Itemize

\series bold
Result
\series default
: An unbiased estimator 
\begin_inset Formula $\hat{\theta}$
\end_inset

 is consistent if 
\begin_inset Formula 
\[
\mathbb{V}(\hat{\theta}_{n})\rightarrow0\quad\text{ \text{ as }}n\rightarrow\infty
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Sufficiency
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
A 
\series bold
\color blue
statistic
\series default
\color inherit
 
\begin_inset Formula $T=t(X_{1},\ldots,X_{n})$
\end_inset

 is a 
\series bold
\color blue
compression of the data
\series default
\color inherit
 into some lower-dimensional quantity.
\end_layout

\begin_layout Itemize
Examples: sample mean 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 or the sample variance 
\begin_inset Formula $s^{2}.$
\end_inset


\end_layout

\begin_layout Itemize
A statistic 
\begin_inset Formula $T=t(X_{1},\ldots,X_{n})$
\end_inset

 is 
\series bold
\color blue
sufficient
\series default
\color inherit
 for a parameter 
\begin_inset Formula $\theta$
\end_inset

 if 
\begin_inset Formula 
\[
\mathrm{Pr}(X_{1},\ldots,X_{n}\vert T=t,\theta)=\mathrm{Pr}(X_{1},\ldots,X_{n}\vert T=t)
\]

\end_inset


\end_layout

\begin_layout Itemize
A 
\series bold
\color blue
sufficient statistic 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
captures all the information in the data about the parameter 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Itemize

\series bold
\color blue
Factorization criterion
\series default
\color inherit
.
 A statistic 
\series bold
\color orange

\begin_inset Formula $T$
\end_inset

 is sufficient for 
\begin_inset Formula $\theta$
\end_inset


\series default
\color inherit
 if and only if the likelihood can be written
\begin_inset Formula 
\[
L(x_{1},\ldots,x_{n}\vert\theta)=g(t,\theta)h(x_{1},\ldots,x_{n}),
\]

\end_inset

where 
\begin_inset Formula $h(x_{1},\ldots,x_{n})$
\end_inset

 is a function that does not involve 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Sufficiency and the MLE
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Assume that a data compression 
\begin_inset Formula $T=t(X_{1},\ldots,X_{n})$
\end_inset

 is sufficient for 
\begin_inset Formula $\theta$
\end_inset

.
 We observe 
\begin_inset Formula $T=t$
\end_inset

.
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize
Since 
\begin_inset Formula $T$
\end_inset

 is sufficient for 
\begin_inset Formula $\theta$
\end_inset

, the log-likelihood can be written
\begin_inset Formula 
\[
\log L(\theta)=\log g(t,\theta)+\log h(x_{1},\ldots,x_{n})
\]

\end_inset


\end_layout

\begin_layout Itemize
The maximum likelihood estimator 
\begin_inset Formula $\hat{\theta}_{ML}$
\end_inset

 is obtained by solving
\begin_inset Formula 
\[
\frac{\mathrm{d}}{\mathrm{d}\theta}\log L(\theta)=\frac{\mathrm{d}}{\mathrm{d}\theta}\log g(t,\theta)
\]

\end_inset


\end_layout

\begin_layout Itemize
It is therefore enough to only keep the compressed data when finding 
\begin_inset Formula $\hat{\theta}_{ML}$
\end_inset

.
 
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\series bold
\color orange
Sufficiency in the iid Poisson model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Likelihood when 
\begin_inset Formula $Y_{1},\ldots,Y_{n}\overset{\mathrm{iid}}{\sim}\mathrm{Pois}(\lambda)$
\end_inset

:
\begin_inset Formula 
\[
L(\lambda)=\prod_{i=1}^{n}\frac{\lambda^{y_{i}}e^{-\lambda}}{y_{i}!}=\frac{\lambda^{n\bar{y}}e^{-n\lambda}}{\prod_{i=1}^{n}y_{i}!}=g(\bar{y},\theta)\cdot h(y_{1},\ldots,y_{n})
\]

\end_inset

where
\begin_inset Formula 
\[
g(\bar{y},\theta)=\lambda^{n\bar{y}}e^{-n\lambda}\qquad\text{ and }\qquad h(y_{1},\ldots,y_{n})=\frac{1}{\prod_{i=1}^{n}y_{i}!}
\]

\end_inset

so 
\begin_inset Formula $\bar{y}$
\end_inset

 is a sufficient statistic for the parameter 
\begin_inset Formula $\lambda$
\end_inset

.
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize
The sample size 
\begin_inset Formula $n$
\end_inset

 is a known constant, not a random variable.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\end_body
\end_document
